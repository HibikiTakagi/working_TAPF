QNet(
  (gcn_conv): GCNConv(3, 3)
  (gcn_conv2): GCNConv(3, 3)
  (gcn_conv3): GCNConv(3, 2)
  (sage_conv): SAGEConv(3, 3, aggr=mean)
  (sage_conv2): SAGEConv(3, 2, aggr=mean)
  (gat_conv): GATConv(3, 3, heads=1)
  (gat_conv2): GATConv(3, 2, heads=1)
  (ln_gcn): LayerNorm(3, affine=True, mode=graph)
  (ln_gcn2): LayerNorm(3, affine=True, mode=graph)
  (ln_gcn3): LayerNorm(2, affine=True, mode=graph)
  (edge_conv): EdgeConv(nn=Sequential(
    (0): Linear(in_features=6, out_features=3, bias=True)
    (1): ReLU()
    (2): Linear(in_features=3, out_features=2, bias=True)
  ))
  (edge_conv2): EdgeConv(nn=Sequential(
    (0): Linear(in_features=4, out_features=2, bias=True)
    (1): ReLU()
    (2): Linear(in_features=2, out_features=2, bias=True)
  ))
  (dropout): Dropout(p=0.5, inplace=False)
  (bn_connect): BatchNorm1d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ln_connect): LayerNorm((108,), eps=1e-05, elementwise_affine=True)
  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (l1): Linear(in_features=108, out_features=1024, bias=True)
  (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (l2): Linear(in_features=1024, out_features=1024, bias=True)
  (l_last): FactorizedNoisy()
  (ladv_last): FactorizedNoisy()
  (lv_last): FactorizedNoisy()
  (flatten): Flatten(start_dim=1, end_dim=-1)
)