Timer unit: 1e-06 s

Total time: 403.059 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: transition at line 273

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   274                                               def transition(self, action):
   325    100100  148658364.4   1485.1     36.9              self.phase3_transition(action) # GNN 35.9 
   338    100100  228882122.4   2286.5     56.8          self.make_observe() # GNN 54.7

Total time: 228.158 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: make_observe at line 386

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   387                                               def make_observe(self):
   389   2004000   10799415.8      5.4      4.7              self.graph.register_robot_data(i, self.robot_envs[i])
   400    100200  176669602.7   1763.2     77.4              self.make_observe_gcn_part_agent_node()
   405    100200   22786830.5    227.4     10.0              self.graph.make_knn_data(self.num_agents)
   406    100200   15807667.5    157.8      6.9              self.convert_and_add_observe(self.each_observation)

Total time: 14.773 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: convert_and_add_observe at line 412

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   413                                               def convert_and_add_observe(self, state):  
   419   2004000   14136554.5      7.1     95.7              self.observation[robot_idx*robot_offset:robot_idx*robot_offset+self.single_obs_dim*KNN_AGENTS] = self.single_state_maker(state, robot_idx)[:]

Total time: 9.95964 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: single_state_maker at line 423

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   424                                               def single_state_maker(self, state, idx):
   426   2104200    2556828.9      1.2     25.7              data = state[self.graph.knn_agents[idx]]
   452   2104200    6983263.3      3.3     70.1              return np.concatenate(data)

Total time: 164.245 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: make_observe_gcn_part_agent_node at line 571

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   572                                               def make_observe_gcn_part_agent_node(self):
   617   2004000   88860535.3     44.3     54.1                                      = self.graph.get_gnn_node_data(robot_id, self.gnn_nodes_from_start)[:]
   623   2004000   30777770.4     15.4     18.7                                      = self.graph.get_gnn_node_data(robot_id, self.gnn_nodes_from_dest)[:]


Total time: 282.084 s
File: /working/AGV_20240529_R4/simulation/QNet.py
Function: forward at line 304

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   305                                               def forward(self, x, local_edge, rows_common, each_info):
   341    100100   54891532.9    548.4     19.5          datasets = [self.make_gnn_dataset(x_infos_batch[b], local_edge[b]) for b in range(batch_num)]
   345    200200   95938719.1    479.2     34.0          for data in dataset_loader: # GNN処理 # GNN 8.5%
   353    100100   30488165.3    304.6     10.8              x_data = self.gcn_conv(x_data, data.edge_index)
   357    100100    5187038.8     51.8      1.8              x_data = self.ln_gcn(x_data)
   372    100100   29245230.9    292.2     10.4              x_data = self.gcn_conv3(x_data, data.edge_index)
   376    100100    4972993.3     49.7      1.8              x_data = self.ln_gcn3(x_data)
   392    100100    3413424.4     34.1      1.2          rows_common = torch.tensor(np.concatenate(rows_common).reshape(batch_num, KNN_AGENTS, -1)).to(DEVICE)
   395    200200     350421.3      1.8      0.1          x_all_info_flats = torch.flatten(
   396    200200    1827567.0      9.1      0.6              torch.stack(
   397    200200   14731915.2     73.6      5.2                  [
   398    100100      37369.4      0.4      0.0                      x_all_infos[batch][rows_common[batch]] for batch in range(batch_num)
   399                                                           ]
   400    100100      16560.9      0.2      0.0              ), start_dim=2
   401                                                   )
   410    100100    5690106.4     56.8      2.0          x = F.relu(self.ln1(self.l1(x)))
   414    100100   10539609.4    105.3      3.7              adv = self.ladv_last(x)
   415    100100    9474388.7     94.6      3.4              v = self.lv_last(x)

Total time: 139.982 s
File: /working/AGV_20240529_R4/simulation/RobotEnvironment.py
Function: transition at line 260

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   261                                               def transition(self, action):
   263   2002000    3741779.9      1.9      2.7          self.next_state[:] = self.lookahead(action)
   264   2002000    3909940.4      2.0      2.8          reward = self.reward_function(action)
   287   2002000  126428780.6     63.2     90.3          self.make_observe(self.next_state) # GNN 85.0

Total time: 289.024 s
File: testing_script.py
Function: make_localedge_numpy at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   127                                               def make_localedge_numpy(self, nodes_numpy ,connect):
   128   2002000   50126596.4     25.0     17.3          node_to_idx = self.make_node_idx(nodes_numpy) # GNN 8.7%
   129                                                   #node_to_idx = {node: idx for idx, node in enumerate(nodes_numpy)} 
   130   2002000    3620651.2      1.8      1.3          nodes_set = set(nodes_numpy)  # Convert to a set for faster lookup # GNN 2.1$
   131   2002000     264823.3      0.1      0.1          edges_from = []
   132   2002000     258137.2      0.1      0.1          edges_to = []
   134  66066000    8504838.7      0.1      2.9          for start_node in nodes_numpy: # GNN 4.7%
   135  64064000    9167673.3      0.1      3.2              start_idx = node_to_idx[start_node] # GNN 3.4%
   137 165689593   76155930.6      0.5     26.3              for dest_node in connect[start_node]: # GNN 34.7%
   138 101625593   61301689.6      0.6     21.2                  if dest_node in nodes_set:        # GNN 20.6%
   139  63318043   56575918.1      0.9     19.6                      dest_idx = node_to_idx[dest_node] # GNN 18.3%
   140  63318043   10709505.0      0.2      3.7                      edges_from.append(start_idx) # GNN 3.6%
   141  63318043   12077813.8      0.2      4.2                      edges_to.append(dest_idx) # GNN 3.5%
   143   2002000     260515.5      0.1      0.1          return [edges_from, edges_to]

Total time: 89.0014 s
File: testing_script.py
Function: make_node_idx at line 148

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   149                                               def make_node_idx(self, nodes_numpy):
   150  20020000    1894465.7      0.1      2.1          ret_dict = {}
   151 212212000   39265660.0      0.2     44.1          for idx, node in enumerate(nodes_numpy):
   152 192192000   23256332.8      0.1     26.1              if node not in ret_dict:
   153 154815870   22977249.4      0.1     25.8                  ret_dict[node] = idx
   154  20020000    1607672.7      0.1      1.8          return ret_dict

Total time: 168.808 s
File: testing_script.py
Function: find_indices at line 156

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   157                                               def find_indices(self, abst_list, nodes_numpy):
   159  18018000  135665417.7      7.5     80.4          nodes_to_idx = self.make_node_idx(nodes_numpy)
   160  18018000   29852196.7      1.7     17.7          indices = [nodes_to_idx[abst] for abst in abst_list]

Total time: 218.352 s
File: testing_script.py
Function: make_rows_agents at line 163

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   164                                               def make_rows_agents(self, nodes_numpy, abst_arrays, connect):
   166    100100   67501861.2    674.3     30.9          rows_common = np.array([np.array(self.find_indices(abst_arrays[i], nodes_numpy[i])) for i in range(self.env.num_agents)])
   173    100100  150374283.1   1502.2     68.9          rows_local = np.array([np.array([self.find_indices(abst_arrays[i][robot], nodes_numpy[i][robot]) for robot in range(KNN_AGENTS)]) for i in range(self.env.num_agents)])

Total time: 1335.31 s
File: testing_script.py
Function: main at line 189

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   190                                               def main(self):
   215    100100  374325637.8   3739.5     28.0              local_edge = self.make_localedge_numpy_agents(sub_graph_node, self.env.connect_dict)
   216    100100  218664504.8   2184.5     16.4              rows_common, rows_local = self.make_rows_agents(sub_graph_node, abst_array, self.env.connect_dict)
   217    100100   23952814.5    239.3      1.8              each_info = self.make_each_info(pre_each_info, rows_local)                                                
   219    100100  296680377.1   2963.8     22.2              action = policy.greedy(observation, (local_edge, rows_common, each_info))
   223    100100  407869904.6   4074.6     30.5              observation_next, reward, terminated, truncated, _ = self.env.step(action)

