Timer unit: 1e-06 s

Total time: 77.0331 s
File: /working/AGV_20240529_R4/simulation/MultiRobotsEnvironment.py
Function: transition at line 274

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   274                                               @profile
   275                                               def transition(self, action):
   326     19377   16519618.8    852.5     21.4              self.phase3_transition(action) # GNN 35.9 
   339     19377   57441399.6   2964.4     74.6          self.make_observe() # GNN 54.7

Total time: 116.535 s
File: /working/AGV_20240529_R4/simulation/QNet.py
Function: forward at line 300

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   300                                               @profile
   301                                               def forward(self, x, local_edge, rows_common, each_info):
   337     31454   28487575.5    905.7     24.4          datasets = [self.make_gnn_dataset(x_infos_batch[b], local_edge[b]) for b in range(batch_num)]
   341     62908   43379786.6    689.6     37.2          for data in dataset_loader: # GNN処理 # GNN 8.5%
   349     31454    9716280.9    308.9      8.3              x_data = self.gcn_conv(x_data, data.edge_index)
   353     31454    1652006.3     52.5      1.4              x_data = self.ln_gcn(x_data)
   354     31454     243430.2      7.7      0.2              x_data = F.relu(x_data)
   357     31454    9325420.6    296.5      8.0              x_data = self.gcn_conv2(x_data, data.edge_index)
   361     31454    1589584.4     50.5      1.4              x_data = self.ln_gcn2(x_data)
   362     31454     227002.6      7.2      0.2              x_data = F.relu(x_data)
   363                                                       
   376     31454    1229336.9     39.1      1.1          rows_common = torch.tensor(np.concatenate(rows_common).reshape(batch_num, KNN_AGENTS, -1)).to(DEVICE)
   379     62908     115230.1      1.8      0.1          x_all_info_flats = torch.flatten(
   380     62908     782186.8     12.4      0.7              torch.stack(
   381     62908    7317992.6    116.3      6.3                  [
   382     31454      11998.0      0.4      0.0                      x_all_infos[batch][rows_common[batch]] for batch in range(batch_num)
   383                                                           ]
   384     31454       5404.8      0.2      0.0              ), start_dim=2
   385                                                   )
   393     31454    1994302.6     63.4      1.7          x = F.relu(self.ln1(self.l1(x)))
   395     31454       5939.7      0.2      0.0          if DUELINGMODE:
   396     31454    3324888.0    105.7      2.9              adv = self.ladv_last(x)
   397     31454    3010117.3     95.7      2.6              v = self.lv_last(x)
   398     31454     224863.5      7.1      0.2              averagea = adv.mean(1, keepdim=True)
   399     31454     471443.0     15.0      0.4              return v.expand(-1, self.action_dims) + (adv - averagea.expand(-1, self.action_dims))

Total time: 80.6174 s
File: savetraining.py
Function: make_localedge_numpy at line 125

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   125                                               @profile # GNN 13% of savetraining.py
   126                                               def make_localedge_numpy(self, nodes_numpy ,connect):
   127    452751   14794435.1     32.7     18.4          node_to_idx = self.make_node_idx(nodes_numpy) # GNN 8.7%
   129    452751     922895.9      2.0      1.1          nodes_set = set(nodes_numpy)  # Convert to a set for faster lookup # GNN 2.1$
   133  18562791    2458436.3      0.1      3.0          for start_node in nodes_numpy: # GNN 4.7%
   134  18110040    2589216.8      0.1      3.2              start_idx = node_to_idx[start_node] # GNN 3.4%
   136  46211058   23213380.2      0.5     28.8              for dest_node in connect[start_node]: # GNN 34.7%
   137  28101018   16625942.1      0.6     20.6                  if dest_node in nodes_set:        # GNN 20.6%
   138  14628521   14796324.9      1.0     18.4                      dest_idx = node_to_idx[dest_node] # GNN 18.3%
   139  14628521    2603592.1      0.2      3.2                      edges_from.append(start_idx) # GNN 3.6%
   140  14628521    2443548.3      0.2      3.0                      edges_to.append(dest_idx) # GNN 3.5%

Total time: 25.614 s
File: savetraining.py
Function: make_node_idx at line 147

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   147                                               @profile
   148                                               def make_node_idx(self, nodes_numpy):
   149   5433012     580281.3      0.1      2.3          ret_dict = {}
   150  59763132   11124833.9      0.2     43.4          for idx, node in enumerate(nodes_numpy):
   151  54330120    6755025.3      0.1     26.4              if node not in ret_dict:
   152  48695953    6698701.2      0.1     26.2                  ret_dict[node] = idx
   153   5433012     455120.7      0.1      1.8          return ret_dict

Total time: 49.0157 s
File: savetraining.py
Function: find_indices at line 155

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   155                                               @profile
   156                                               def find_indices(self, abst_list, nodes_numpy):
   158   4980261   39569088.1      7.9     80.7          nodes_to_idx = self.make_node_idx(nodes_numpy)
   159   4980261    8439401.6      1.7     17.2          indices = [nodes_to_idx[abst] for abst in abst_list]

Total time: 63.2007 s
File: savetraining.py
Function: make_rows_agents at line 162

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   162                                               @profile
   163                                               def make_rows_agents(self, nodes_numpy, abst_arrays, connect):
   165     34827   19311187.6    554.5     30.6          rows_common = np.array([np.array(self.find_indices(abst_arrays[i], nodes_numpy[i])) for i in range(self.env.num_agents)])
   172     34827   43720555.7   1255.4     69.2          rows_local = np.array([np.array([self.find_indices(abst_arrays[i][robot], nodes_numpy[i][robot]) for robot in range(KNN_AGENTS)]) for i in range(self.env.num_agents)])
   173                                                   

Total time: 424.709 s
File: savetraining.py
Function: main at line 189

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   189                                               @profile
   190                                               def main(self):
   236     15451   45230520.8   2927.4     10.6                  local_edge = self.make_localedge_numpy_agents(sub_graph_node, self.env.connect_dict)
   237     15451   28164176.6   1822.8      6.6                  rows_common, rows_local = self.make_rows_agents(sub_graph_node, abst_array, self.env.connect_dict)
   238     15451    3085769.2    199.7      0.7                  each_info = self.make_each_info(pre_each_info, rows_local)
   239                                                           
   240     15451   39294260.9   2543.2      9.3                  action = policy.epsilon_greedy(observation, (local_edge, rows_common, each_info)) # get next action from policy # GNN 14.8%
   241                                                           
   242     15451   62049007.8   4015.9     14.6                  observation_next, reward, terminated, truncated, _ = self.env.step(action) # do action
   243                                                           
   244     15450     870908.8     56.4      0.2                  sub_graph_node_next, abst_array_next, pre_each_info_next = self.get_nodes(observation_next)
   245     15450   45516116.9   2946.0     10.7                  local_edge_next = self.make_localedge_numpy_agents(sub_graph_node_next, self.env.connect_dict)
   246     15450   28026009.7   1814.0      6.6                  rows_common_next, rows_local_next = self.make_rows_agents(sub_graph_node_next, abst_array_next, self.env.connect_dict)
   247     15450    3054942.1    197.7      0.7                  each_info_next = self.make_each_info(pre_each_info_next, rows_local_next)
   248                                           
   262     30676    4051928.4    132.1      1.0                          self.replay_buffer.add(
   263     30676      20865.4      0.7      0.0                              (replay_obs.copy(), action[0], reward, replay_obs_next.copy(), terminated, 
   264     15338       6579.7      0.4      0.0                               local_edge[0], rows_common[0], each_info[0],
   265     15338       4603.2      0.3      0.0                               local_edge_next[0], rows_common_next[0], each_info_next[0]))
   278      3057  112038134.9  36649.7     26.4                      policy.train_batch(batch=self.replay_buffer.sample(BATCH_SIZE)) # TRAIN from replay # GNN 73.0%
   302      3926   11665444.1   2971.3      2.7                      local_edge = self.make_localedge_numpy_agents(sub_graph_node, self.env.connect_dict)
   303      3926    7125276.4   1814.9      1.7                      rows_common, rows_local = self.make_rows_agents(sub_graph_node, abst_array, self.env.connect_dict)
   304      3926     781829.7    199.1      0.2                      each_info = self.make_each_info(pre_each_info, rows_local)
   306      3926   10070783.9   2565.2      2.4                      action = policy.target_greedy(observation, (local_edge, rows_common, each_info)) # GNN4.9%
   308      3926   15587817.0   3970.4      3.7                      observation_next, reward, terminated, truncated, _ = self.env.step(action) 


   ###      3926   11665444.1   2971.3     24.0                      self.make_localedge_numpy_agents(sub_graph_node, self.env.connect_dict)
   ###     15451   28164176.6   1822.8     14.3                      self.make_rows_agents(sub_graph_node, abst_array, self.env.connect_dict)
   ###      3926     781829.7    199.1      1.6                      self.make_each_info(pre_each_info, rows_local)
   278      3057  112038134.9  36649.7     26.4                      policy.train_batch(batch=self.replay_buffer.sample(BATCH_SIZE)) # TRAIN from replay
   308      3926   15587817.0   3970.4     18.3                      self.env.step(action) 
   240     15451   39294260.9   2543.2      9.3                      policy.greedy(observation, (local_edge, rows_common, each_info)) # get next action from policy
